{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db02c15e",
   "metadata": {},
   "source": [
    "### Note: \n",
    "\n",
    "Some functions can be useless for you, for example normalizing the datas. The path have to be changed. You can change the padding with whatever you want. We keep the subject number and experiment number dependencies because we believed that the EEG signals can changed without outside unknown parammeters like the level of stress, of happiness, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e113633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import pandas as pd \n",
    "import torch\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a434b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5ee635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful functions\n",
    "\n",
    "def import_matfiles(path):\n",
    "    list_mat_ex = os.listdir(path2)\n",
    "    #list_mat_file contains all interessant files for our research\n",
    "    list_mat_ex.remove('readme.txt')\n",
    "    #list_mat_file contains all interessant files for our research\n",
    "    label = list_mat_ex[-1]\n",
    "    print(label)\n",
    "    list_mat_ex.pop(-1)\n",
    "    return list_mat_ex, label\n",
    "    \n",
    "def find_max_shape(datas, freq = None):\n",
    "    #shape of data in datas (freq, nb channel, activity)\n",
    "    if freq == None:\n",
    "        max_ = datas[0].shape[2]\n",
    "        for data in datas[1:]:\n",
    "            act_shape = data.shape[2]\n",
    "            if act_shape > max_ :\n",
    "                max_ = act_shape\n",
    "    else :\n",
    "        #hape of data in datas (nb channel, activity)\n",
    "        max_ = datas[0].shape[1]\n",
    "        for data in datas[1:]:\n",
    "            act_shape = data.shape[1]\n",
    "            if act_shape > max_ :\n",
    "                max_ = act_shape\n",
    "    return max_  \n",
    "\n",
    "def x_shaper(x):\n",
    "    \"\"\"\n",
    "    Arg: x as when it outcome from the dataset\n",
    "    return: x as we wants tensor with (freq, nb_channel, activity)\n",
    "    \"\"\"\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    return torch.from_numpy(x).type(torch.float32)\n",
    "\n",
    "def datas_shaper(datas):\n",
    "    res = []\n",
    "    for data in datas:\n",
    "        print(data.shape)\n",
    "        res.append(x_shaper(data))\n",
    "    return res \n",
    "\n",
    "def padd(datas, freq = None):\n",
    "    #shape of data in datas (freq, nb channel activity)\n",
    "    max_shape = find_max_shape(datas, freq =freq)\n",
    "    res = []\n",
    "    if freq == None :\n",
    "        for data in datas:\n",
    "            aux = torch.zeros((data.shape[0], data.shape[1], max_shape))\n",
    "            if data.shape[2] < max_shape:\n",
    "                add_shape = max_shape - data.shape[2]\n",
    "                for freq in range(data.shape[0]):\n",
    "                    pad_tensor = torch.zeros((data.shape[1], add_shape))\n",
    "                    aux[freq, :, :] = torch.cat((data[freq, :, :], pad_tensor), dim=1)\n",
    "                    aux = aux.type(torch.float32)\n",
    "                res.append(aux)\n",
    "            else :\n",
    "                res.append(data.type(torch.float32))\n",
    "    else :\n",
    "        for data in datas:\n",
    "            aux = torch.zeros((data.shape[0], max_shape))\n",
    "            if data.shape[1] < max_shape:\n",
    "                add_shape = max_shape - data.shape[1]\n",
    "                pad_tensor = torch.zeros((data.shape[0], add_shape))\n",
    "                aux = torch.cat((data, pad_tensor), dim=1)\n",
    "                aux = aux.type(torch.float32)\n",
    "                res.append(aux)\n",
    "            else :\n",
    "                res.append(data.type(torch.float32))\n",
    "    return res\n",
    "\n",
    "def normalize(x, freq = None):\n",
    "    if freq == None:\n",
    "        for frequencies in range(x.shape[0]):\n",
    "            mean_ = torch.mean(x[frequencies, :, :], 1).reshape(-1, 1)\n",
    "            std_ = torch.std(x[frequencies, : ,: ], 1).reshape(-1, 1)\n",
    "            x[frequencies, :, :] = (x[frequencies, :, :] - mean_) / std_\n",
    "            return x\n",
    "    else :\n",
    "        mean_ = torch.mean(x[freq, :, :], 1).reshape(-1, 1)\n",
    "        std_ = torch.std(x[freq, : ,: ], 1).reshape(-1, 1)\n",
    "        x[freq, :, :] = (x[freq, :, :] - mean_) / std_\n",
    "        return x[freq, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1e59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version to improve in a near future..\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, path, signals, subject_number, experiment_number, labels, smoothing_method, multifreq = False):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            path: path to folder with all the .mat files of the dataset\n",
    "            signals: feature that we want to extract\n",
    "            subject_number: subject of the experimenr\n",
    "            epxeriment_number: number of the experiment, like 0 week 1 week or 2 week \n",
    "            (MAYBE I MISUNDERSTOOD THIS PART READ AGAIN DATASET DETAILS)\n",
    "            labels: labels list\n",
    "            smoothing method: movingAve or LDS\n",
    "        \"\"\"\n",
    "        list_file, _ = import_matfiles(path)\n",
    "        #selection of interesting files that means the one related to the subject\n",
    "        list_sub_file = []\n",
    "        for file in list_file:\n",
    "            num = file.split('_')[0]\n",
    "            if int(num) == subject_number: \n",
    "                list_sub_file.append(file)\n",
    "             \n",
    "        working_file = list_sub_file[experiment_number]\n",
    "        \n",
    "        dic = loadmat(path + '\\\\' + working_file) \n",
    "        if smoothing_method == 'movingAve':\n",
    "            smooth = signals.lower() + '_movingAve'\n",
    "        elif smooting_method == 'LDS':\n",
    "            smooth = signals.lower() + '_LDS'\n",
    "        else :\n",
    "            raise ValueError('Please select a good smoothing method: movingAve or LDS')\n",
    "        \n",
    "        #maybe a list is not the best tool to store it\n",
    "        datas = []\n",
    "        for k in range(15):\n",
    "            sig = dic[smooth + str(k+1)]\n",
    "            sig = x_shaper(sig)\n",
    "            sig = normalize(sig, freq = 0) #change the freq if needed!!!!!!!!!!!!\n",
    "            datas.append(sig)\n",
    "            \n",
    "        \n",
    "        datas = padd(datas, freq = 0) #everything is happening in this function, the changement from Long to Float\n",
    "                                    #and the slicing for the frequency we want\n",
    "\n",
    "        labels = labels.reshape(-1, )\n",
    "        labels = labels + 1 #sliding to use CrossEntropy Pytorch function\n",
    "        labels = torch.from_numpy(labels)\n",
    "                                  \n",
    "                                  \n",
    "        self.datas = datas\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.datas[idx], self.labels[idx].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8733784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.mat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path2 = r'C:\\Users\\harol\\UsefulCode\\CP_DSAI\\Project\\Dataset\\SEED\\ExtractedFeatures'\n",
    "l, label_ = import_matfiles(path2)\n",
    "labels = loadmat(path2 + '\\\\' + label_)['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c48162e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.mat\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\harol\\UsefulCode\\CP_DSAI\\Project\\Dataset\\SEED\\ExtractedFeatures'\n",
    "signals = 'de'\n",
    "subject_number = 4\n",
    "experiment_number = 0\n",
    "labels = labels\n",
    "smoothing_method = 'movingAve'\n",
    "dataset = SignalDataset(path, signals, subject_number, experiment_number, labels, smoothing_method)\n",
    "train_dataset, test_dataset = random_split(dataset, [9, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b1d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "9 6\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2edb3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
